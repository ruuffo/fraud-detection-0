{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud detection\n",
    "\n",
    "In this workbook, we will attempt to understand and study an unbalanced data set containing fraudulent bank transactions. Our main goal will be to detect these undesirable transactions with as few errors as possible.\n",
    "\n",
    "Our dataset comes from Kaggle, which can be found at the following URL: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\n",
    "\n",
    "## Setting-Up\n",
    "\n",
    "### Create and activate virtual environment\n",
    "The first step is to set up the Python virtual environment, in first with the creation of the environnement, and then install dependencies using the [requirements.txt](requirements.txt) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m venv venv\n",
    "!source venv/bin/activate\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a3c0b7d-66bb-4dc2-bd7b-64a240e5862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "import kaggle\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from Kaggle\n",
    "\n",
    "You can download the dataset either by using a Kaggle API key that you can configure in your account settings (see [here](https://github.com/Kaggle/kaggle-api/blob/main/docs/README.md#api-credentials)), or by downloading directly from the dataset page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca34fe4-7835-4f20-b7d3-640ae02356be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    if not os.path.exists(\"data\"):\n",
    "        kaggle.api.dataset_download_files(\"mlg-ulb/creditcardfraud\")\n",
    "\n",
    "        with zipfile.ZipFile(\"creditcardfraud.zip\", \"r\") as zip_ref:\n",
    "            zip_ref.extractall(\"data\")\n",
    "\n",
    "        zip_fraud_path = os.path.abspath(\"./creditcardfraud.zip\")\n",
    "        os.remove(zip_fraud_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05bf5449-3987-4ca3-bc63-8b9b7df40a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data()\n",
    "\n",
    "df = pd.read_csv(\"data/creditcard.csv\")\n",
    "TARGET_COLUMN_NAME = \"Class\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "Exploring the data here isn't very instructive, because for reasons of anonymity, the bank data. The transactions have undergone a dimension reduction, which explains why the column names are not very explicit. However, we can already see the imbalance of our target class, namely the “Class” column, which is worth 1 if the transaction seems fraudulent, and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea9b36ae-a7c1-44b3-912f-c0fd060d11bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " Class\n",
       " 0    284315\n",
       " 1       492\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_df_info(p_df: pd.DataFrame):\n",
    "    return p_df.info(), p_df[TARGET_COLUMN_NAME].value_counts()\n",
    "\n",
    "\n",
    "get_df_info(p_df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In percentage terms, over 99% of transactions are regular. This could pose a problem when training our model, which could be confronted with problems of over-fitting to the negative class, and thus distorting the metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[TARGET_COLUMN_NAME].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "The solution is therefore to rebalance the dataset between negative and positive classes. For this, two methods are available: undersampling and oversampling.\n",
    "\n",
    "### Undersampling\n",
    "\n",
    "Undersampling consists in reducing the number of data items in the over-represented class - regular transactions - until the number of data items in the negative class is of the same order of magnitude as that in the positive class.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e71429b-8d1d-44ff-9a49-36ed3b00efa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "1    492\n",
       "0    492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def undersample(p_df: pd.DataFrame):\n",
    "    df_non_fraud = p_df[p_df[TARGET_COLUMN_NAME] == 0]\n",
    "    df_fraud = p_df[p_df[TARGET_COLUMN_NAME] == 1]\n",
    "\n",
    "    df_non_fraud_undersampled = df_non_fraud.sample(df_fraud.shape[0],\n",
    "                                                    random_state=42)\n",
    "\n",
    "    df_balanced_undersampled = pd.concat([df_fraud, df_non_fraud_undersampled])\n",
    "    df_balanced_undersampled[TARGET_COLUMN_NAME].value_counts()\n",
    "    return df_balanced_undersampled\n",
    "\n",
    "\n",
    "df_balanced_undersampled = undersample(df)\n",
    "df_balanced_undersampled[TARGET_COLUMN_NAME].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test the performance of a model, such as a DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe22e45-f459-4c3d-9a2f-e4bbd9e0253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_X_y(df_param: pd.DataFrame):\n",
    "    X = df_param.drop(columns=[TARGET_COLUMN_NAME])\n",
    "    y = df_param[TARGET_COLUMN_NAME]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def train_model_and_predict(df_param: pd.DataFrame) -> pd.Series:\n",
    "    data, target = split_X_y(df_param)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                        target,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=42)\n",
    "\n",
    "    dec_tree = DecisionTreeClassifier()\n",
    "\n",
    "    dec_tree.fit(X_train, y_train)\n",
    "\n",
    "    y_predict = dec_tree.predict(X_test)\n",
    "    return y_test, y_predict, dec_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c8ec9e-2313-4572-88aa-aa6a9a37efcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0  87  11\n",
       "1  11  88"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test, y_predict, dec_tree = train_model_and_predict(df_balanced_undersampled)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca025a-f95f-454e-a6f5-79426913b17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        98\n",
      "           1       0.89      0.89      0.89        99\n",
      "\n",
      "    accuracy                           0.89       197\n",
      "   macro avg       0.89      0.89      0.89       197\n",
      "weighted avg       0.89      0.89      0.89       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're already seeing good performance, with almost 90% good predictions on all classes, but now let's try oversampling to see if we get better diagnoses.\n",
    "\n",
    "### Oversampling\n",
    "\n",
    "Oversampling consists in artificially increasing the number of data items in the minority class, until it is of the same order of magnitude as the majority class. There are several ways of increasing the number of data items in the minority class; here, for example, we use the KMeans method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c2b716-ac00-4e49-b0cd-fb5adcf20f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1    284315\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def oversample(p_df: pd.DataFrame):\n",
    "    X = p_df.drop(columns=[TARGET_COLUMN_NAME])\n",
    "    y = p_df[TARGET_COLUMN_NAME]\n",
    "    smote = SMOTE()\n",
    "    df_data_oversampled, df_target_oversampled = smote.fit_resample(X, y)\n",
    "    return df_data_oversampled, df_target_oversampled\n",
    "\n",
    "\n",
    "df_data_oversampled, df_target_oversampled = oversample(df)\n",
    "df_target_oversampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a458774-d26c-4279-959b-9b18adc78161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oversampled = df_data_oversampled.assign(\n",
    "    **{TARGET_COLUMN_NAME: df_target_oversampled})\n",
    "y_test, y_predict, dec_tree = train_model_and_predict(df_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319ba22-a248-4d0c-bb02-307783d2a300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56613</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>56920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0  56613    137\n",
       "1     56  56920"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac7c7e-e0ce-4aa5-acec-9ce1657f128d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56750\n",
      "           1       1.00      1.00      1.00     56976\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling enables us to obtain highly satisfactory results, with near-perfect class detection on the oversampled set.\n",
    "\n",
    "Now let's try our trained model on the starting data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b90f8c3-5960-4c3f-95e3-820a898b802b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284178</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1\n",
       "0  284178  137\n",
       "1       5  487"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = split_X_y(df)\n",
    "y_predict = dec_tree.predict(X)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b8c251-1e62-4da8-8b72-0801b1985741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    284315\n",
      "           1       0.78      0.99      0.87       492\n",
      "\n",
      "    accuracy                           1.00    284807\n",
      "   macro avg       0.89      0.99      0.94    284807\n",
      "weighted avg       1.00      1.00      1.00    284807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of our model on the initial dataset is highly satisfactory: we have excellent recall on the positive class, with only 5 transactions misclassified out of 492 fraudulent transactions. However, the precision on the positive class is relatively low. Nevertheless, this is not too concerning, as the most important aspect is that all fraudulent transactions have been detected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
